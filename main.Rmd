---
title: ""
output: bookdown::html_document2
bibliography: reference.bib
date: "2025-10-22"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Introduction {#sec1}

本文档旨在完善Bayesian统计在临床试验中应用时涉及的算法。本文档所考虑的先验仅包括混合先验和幂先验。在章节\@ref(sec2)中，本文档将简介混合先验及幂先验的统计学理论。在章节\@ref(sec3)中，本文档将基于SAP模板中的主要分析方法 (MMRM、ANCOVA、negative binomial regression、stratified CMH以及stratified Cox-PH regression)，给出相应的基于混合先验以及幂先验的Bayesian算法框架。在章节\@ref(sec4)中，本文档将基于不同场景下的模拟案例，就参数估计和假设检验，比较不同类型的先验下，频率学方法以及Bayesian方法的统计性能。

# Method and Notation {#sec2}

令$D$表示分析数据，$D_{hst}$表示历史数据，$\theta$表示模型参数，$w\in [0, 1]$表示混合先验权重或幂先验的幂次。此外，对于具体的模型，令$(Y, A, Z)$分别表示分析数据的结局、治疗分组和协变量，$(Y_{hst}, A_{hst}, Z_{hst})$分别表示历史数据的结局、治疗分组和协变量，$i=1,\dots,n$表示个体的下标。

本文档用$p_{hst}(\theta|D_{hst})\propto L(\theta|D_{hst})\pi_0(\theta)$表示信息先验，其中$\pi_0(\theta)$通常取Jeffreys' prior等无信息先验或模糊先验 [@Schmidli2014; @Ibrahim2015; @Yang2023]。

## 混合先验  

混合先验将信息先验$p_{hst}(\theta|D_{hst})$和给定先验$\pi_{vag}(\theta)$按一定的权重混合，其中，$\pi_{vag}(\theta)$通常取弱信息共轭先验（如对二分类终点，可取Jeffreys' prior；对其他终点可取unit information prior）[@Kass1995; @Schmidli2014]，
$$p_{mp}(\theta|w) \propto wp_{hst}(\theta|D_{hst})+(1-w)\pi_{vag}(\theta).$$
若无法确定$w$的值，可将$w$也看作随机变量，此时将由分析数据自适应决定权重分配,
$$p_{mp}(\theta,w)\propto\left(wp_{hst}(\theta|D_{hst})+(1-w)\pi_{vag}(\theta)\right)\pi(w).$$

## 幂先验

幂先验的表达式如下：
$$p_{pp}(\theta|w) \propto L(\theta|D_{hst})^w\pi_0(\theta).$$
从表达式不难得出，当$w=0$时，幂先验不借用历史数据$D_{hst}$；当 $w=1$时，幂先验完全借用历史数据$D_{hst}$。

同样地，若无法确定$w$的值，幂先验也可将$w$也看作随机变量，此时有
$$p_{pp}(\theta,w)\propto L(\theta|D_{hst})^w\pi_0(\theta)\pi(w).$$
然而，与混合先验不同的是，若不对$L(\theta|D_{hst})^w\pi_0(\theta)$标准化，该幂先验会违背Likelihood Principle [@Robert2007; @Berry2010]：当历史数据相同时，对历史数据取不同的充分统计量，得到的先验分布也会不同，因而会产生不同的推断结果。因此，在将$w$看作随机变量时，需要进行如下标准化，
$$p_{pp}(\theta,w)=p_{pp}(\theta|w)\pi(w)=\frac{L(\theta|D_{hst})^w\pi_0(\theta)}{\int L(\theta|D_{hst})^w\pi_0(\theta)d\theta}\pi(w).$$

# Application and Case Study {#sec3}

## 非肿瘤项目

### 连续变量终点

#### MMRM模型

#### ANCOVA模型

##### 固定权重

ANCOVA的模型假设如下：
$$Y_i=\alpha+\tau A_i+Z_i^T\gamma+\varepsilon_i, \varepsilon_i\sim N(0, \sigma^2).$$
也即，
$$Y\sim N(X\beta, \sigma^2I),$$
其中$X=[1, A, Z]$，$\beta = [\alpha, \tau, \gamma^T]^T$。那么对于历史数据，取Jeffreys prior $\pi_{hst}(\beta,\sigma^2)\propto 1/\sigma^2$，有
\begin{equation*}
\begin{aligned}
p_{hst}(\theta|D_{hst}) & \propto (\sigma^2)^{-\frac{n}{2}-1}\exp\left\{-\frac{1}{2}(\sigma^2)^{-1}(Y_{hst}-X_{hst}\beta)^T(Y_{hst}-X_{hst}\beta)\right\}\\
&=N\left(\hat\beta_{hst},\sigma^2(X_{hst}^TX_{hst})^{-1}\right)InvGamma\left(\frac{n-p}{2},\frac{RSS_{hst}}{2}\right),
\end{aligned}
\end{equation*}
因此，混合先验为
$$p_{mp}(\beta,\sigma^2|w)\sim wp_{hst}(\theta|D_{hst})+(1-w)\pi_{vag}(\beta,\sigma^2).$$
对于$\pi_{vag}(\beta,\sigma^2)$的选取，由于涉及联合先验，此处可选择弱信息共轭先验，例如$\pi_{vag}(\beta,\sigma^2)=N(\hat\beta_{hst},n\sigma^2(X_{hst}^TX_{hst})^{-1})\cdot$$InvGamma(\frac{1}{2}, \frac{RSS_{hst}}{2})$。


幂先验为 [@Ibrahim2003]
\begin{equation*}
\begin{aligned}
p_{pp}(\beta,\sigma^2|w)&\propto (\sigma^2)^{-\frac{nw}{2}-1}\exp\left\{-\frac{1}{2}(\sigma^2/w)^{-1}(Y_{hst}-X_{hst}\beta)^T(Y_{hst}-X_{hst}\beta)\right\}\\ &=N\left(\hat\beta_{hst},w^{-1}\sigma^2(X_{hst}^TX_{hst})^{-1}\right)InvGamma\left(\frac{nw-p}{2},\frac{wRSS_{hst}}{2}\right).
\end{aligned}
\end{equation*}
注意到当$w\leq p/n$时，幂先验可能为improper prior。

##### 随机权重

## 肿瘤项目

# Simulation Study {#sec4}

## 非肿瘤项目

### 连续变量终点

#### MMRM模型

#### ANCOVA模型

以下为ANCOVA

```{r}
library(rstan)
rstan_options(auto_write = TRUE)
options(mc.cores = min(parallel::detectCores()-1, 8))

# --- Helper: build design matrices ---
mk_design <- function(df, formula) {
  mm <- model.matrix(formula, df)
  Y <- model.response(model.frame(formula, df))
  list(Y = as.numeric(Y), X = mm, cols = colnames(mm))
}

# --- Derive Normal–Inverse-Gamma prior from historical data ---
nig_from_history <- function(X, Y) {
  n <- nrow(X)
  p <- ncol(X)
  fit <- lm.fit(X, Y)
  beta <- coef(fit)
  RSS <- sum(residuals(fit)^2)
  XtX <- solve(crossprod(X))
  L_Sigma <- t(chol(XtX))

  # Scaled by power a0 for power prior
  a <- (n - p)/2
  b <- RSS/2

  list(beta = beta, L_Sigma = L_Sigma, RSS = RSS, a = a, b = b)
}

# --- Construct data list for Stan ---
build_ancova_data <- function(df_cur, df_hst, formula,
                              w_fixed = 0.5, estimate_w = FALSE,
                              beta_vag = NULL, scale_vag = NULL,
                              a_vag = NULL, b_vag = NULL) {
  #prior_type <- match.arg(prior_type)
  des_cur <- mk_design(df_cur, formula)
  des_hst <- mk_design(df_hst, formula)

  # historical informative prior (scaled by a0)
  hist_info_mp <- nig_from_history(des_hst$X, des_hst$Y)
  #hist_info_a0 <- nig_from_history(des_hist$X, des_hist$y, a0 = a0_power)
  
  # vague prior
  if (is.null(beta_vag)) {
    beta_vag <- hist_info_mp$beta
  }
  if (is.null(scale_vag)) {
    L_Sigma_vag <- sqrt(nrow(des_hst$X))*hist_info_mp$L_Sigma
  } else {
    L_Sigma_vag <- t(chol(scale_vag))
  }
  if (is.null(a_vag)) {
    a_vag <- 1/2
  }
  if (is.null(b_vag)) {
    b_vag <- 1/2*hist_info_mp$RSS
  }
  
  # ll0_hat = log-likelihood of historical data at MLE (for CPP normalization)
  #ll0_hat <- as.numeric(logLik(lm(des_hst$y ~ des_hst$X - 1)))

  list(
    n = nrow(des_cur$X),
    p = ncol(des_cur$X),
    Y = des_cur$Y,
    X = des_cur$X,
    beta_hst = hist_info_mp$beta,
    L_Sigma_hst = hist_info_mp$L_Sigma,
    a_hst = hist_info_mp$a,
    b_hst = hist_info_mp$b,
    beta_vag = beta_vag,
    L_Sigma_vag = L_Sigma_vag,
    a_vag = a_vag,
    b_vag = b_vag,
    #prior_type = ifelse(prior_type=="mixture", 1L, 2L),
    w_fixed = w_fixed,
    #a0_fixed = a0_fixed,
    estimate_w = as.integer(estimate_w)
    #estimate_a0 = as.integer(estimate_a0),
    #n_hst = nrow(des_hst$X),
    #p_hst = ncol(des_hst$X),
    #Y_hst = des_hst$Y,
    #X_hst = des_hst$X
    #ll0_hat = ll0_hat
  )
}

# --- Run Stan model ---
run_ancova_conjugate <- function(df_cur, df_hst, formula,
                                 #prior_type = c("mixture","power"),
                                 w_fixed = 0.5, estimate_w = FALSE,
                                 #a0_fixed = 0.5, estimate_a0 = FALSE,
                                 #a0_power = 0.5,
                                 iter = 5000, burnin = iter/2, chains = 4, seed = 123) {
  # dat <- build_ancova_data(df_cur, df_hst, formula,
  #                          prior_type, w_fixed, estimate_w,
  #                          a0_fixed, estimate_a0,
  #                          a0_power = a0_power)
  dat <- build_ancova_data(df_cur, df_hst, formula,
                           w_fixed, estimate_w)
  

  stan_file <- "ancova_conj_mp.stan"
  fit <- stan(file = stan_file, data = dat, iter = iter, warmup = burnin, chains = chains, seed = seed, save_warmup = FALSE)
  return(fit)
}

# --- Extract treatment effect posterior ---
extract_tau <- function(fit_obj, tau_col) {
  sm <- rstan::summary(fit_obj, pars = "beta")$summary
  idx <- match(tau_col, fit_obj$dat$cols)
  sm[idx, c("mean","2.5%","50%","97.5%","n_eff","Rhat")]
}

# --- Simulation ---
n <- 500
n_hst <- 300
n_cur <- n - n_hst
alpha <- 3
tau <- -5
gamma <- 0.9
treatment <- rbinom(n, 1, 0.5)
score_baseline <- sample(20:55, n, replace = T)
e <- rnorm(n, sd = 3)
score <- round(alpha + tau*treatment + gamma*score_baseline + e)
data <- data.frame(score_baseline, treatment, score)
data_hst <- data[1:n_hst,]
data_cur <- data[(n_hst+1):n,]
fit_conj_mp <- run_ancova_conjugate(data_cur, data_hst, score ~ score_baseline + treatment, chains = 4)

```


# Reference {#sec5}